{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection\n",
    "\n",
    "The following are potential models that I've toyed with a little bit in order to make the decision of the best model choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subreddit</th>\n",
       "      <th>Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24hoursupport</td>\n",
       "      <td>['like', 'helping', 'come', 'hang', 'new', 'di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24hoursupport</td>\n",
       "      <td>['acer', 'laptop', 'corrupt', 'windows', 'turn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24hoursupport</td>\n",
       "      <td>['downloaded', 'trojan', 'file', 'window', 'de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24hoursupport</td>\n",
       "      <td>['use', 'help', 'accessed', 'smart', 'remote',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24hoursupport</td>\n",
       "      <td>['problem', 'network', 'adapter', 'i’m', 'havi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Subreddit                                             Tokens\n",
       "0  24hoursupport  ['like', 'helping', 'come', 'hang', 'new', 'di...\n",
       "1  24hoursupport  ['acer', 'laptop', 'corrupt', 'windows', 'turn...\n",
       "2  24hoursupport  ['downloaded', 'trojan', 'file', 'window', 'de...\n",
       "3  24hoursupport  ['use', 'help', 'accessed', 'smart', 'remote',...\n",
       "4  24hoursupport  ['problem', 'network', 'adapter', 'i’m', 'havi..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split\n",
    "\n",
    "\n",
    "df = pd.read_csv('../data/datasets/cleaned_data.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((898, 2), (385, 2))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train-Test Split\n",
    "\n",
    "train, test = train_test_split(df, train_size=0.7, random_state=42)  # 70/30 Train-Test Split\n",
    "\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:\n",
      "Train: (898,)\n",
      "Test: (385,)\n",
      "\n",
      "y:\n",
      "Train: (898,)\n",
      "Test: (385,)\n"
     ]
    }
   ],
   "source": [
    "X_train = train['Tokens']\n",
    "y_train = train['Subreddit']\n",
    "\n",
    "X_test = test['Tokens']\n",
    "y_test = test['Subreddit']\n",
    "\n",
    "print('X:')\n",
    "print('Train:', X_train.shape)\n",
    "print('Test:', X_test.shape)\n",
    "\n",
    "print()  # For improved readability\n",
    "\n",
    "print('y:')\n",
    "print('Train:', y_train.shape)\n",
    "print('Test:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF Vectorizer / Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy Score: 0.5246753246753246\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Not using Tokenizer parameter because we've already tokenized our input in preprocessing.\n",
    "vect = TfidfVectorizer()\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "pipe = Pipeline([('vect', vect), ('clf', rfc)])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "print('Baseline Accuracy Score:', pipe.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'vect__ngram_range': [(1, 1), (1, 2), (1, 3),\n",
    "                                    (1, 4), (1, 5), (1, 6),\n",
    "                                    (2, 3), (2, 4), (2, 5)],\n",
    "              'vect__analyzer': ['word', 'char', 'char_wb'],\n",
    "              'vect__norm': ['l1', 'l2']}\n",
    "search = RandomizedSearchCV(pipe, parameters, n_iter=40, cv=5, n_jobs=-1, verbose=False)\n",
    "results = search.fit(X_train, y_train)\n",
    "\n",
    "vect__ngram_range = results.best_params_['vect__ngram_range']\n",
    "vect__analyzer = results.best_params_['vect__analyzer']\n",
    "vect__norm = results.best_params_['vect__norm']\n",
    "\n",
    "print('Best Score:', results.best_score_)\n",
    "print('Achieved With Parameters:', results.best_params_)\n",
    "print('Evaluation:', search.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'vect__ngram_range': [vect__ngram_range],\n",
    "              'vect__analyzer': [vect__analyzer],\n",
    "              'vect__norm': [vect__norm],\n",
    "              'clf__n_estimators': [25, 50, 100, 125, 150, 175, 200, 225, 250, 300],\n",
    "              'clf__max_features': [None, 'sqrt', 'log2', 50, 100, 200, 250],\n",
    "              'clf__class_weight': ['balanced', 'balanced_subsample'],\n",
    "              'clf__oob_score': [True, False]}\n",
    "\n",
    "search = RandomizedSearchCV(pipe, parameters, n_iter=40, cv=5, n_jobs=-1, verbose=False)\n",
    "results = search.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "clf__n_estimators = results.best_params_['clf__n_estimators']\n",
    "clf__max_features = results.best_params_['clf__max_features']\n",
    "clf__class_weight = results.best_params_['clf__class_weight']\n",
    "clf__oob_score = results.best_params_['clf__oob_score']\n",
    "\n",
    "print('Best Score:', results.best_score_)\n",
    "print('Achieved With Parameters:', results.best_params_)\n",
    "print('Evaluation:', search.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'vect__analyzer': [vect__analyzer],\n",
    "              'vect__ngram_range': [vect__ngram_range],\n",
    "              'vect__norm': [vect__norm],\n",
    "              'clf__n_estimators': [clf__n_estimators],\n",
    "              'clf__max_features': [clf__max_features],\n",
    "              'clf__class_weight': [clf__class_weight],\n",
    "              'clf__oob_score': [clf__oob_score],\n",
    "              'clf__max_depth': [None, 5, 10, 25, 50, 100, 150, 250],\n",
    "              'clf__min_samples_leaf': [1, 2.5, 5, 10, 25, 50],\n",
    "              'clf__max_leaf_nodes': [None, 2, 3, 5, 10, 15, 25, 50]}\n",
    "\n",
    "search = RandomizedSearchCV(pipe, parameters, n_iter=40, cv=5, n_jobs=-1, verbose=False)\n",
    "results = search.fit(X_train, y_train)\n",
    "\n",
    "clf__max_depth = results.best_params_['clf__max_depth']\n",
    "clf__min_samples_leaf = results.best_params_['clf__min_samples_leaf']\n",
    "clf__max_leaf_nodes = results.best_params_['clf__max_leaf_nodes']\n",
    "\n",
    "\n",
    "print('Best Score:', results.best_score_)\n",
    "print('Achieved With Parameters:', results.best_params_)\n",
    "print('Evaluation (TF-IDF / RFC):', search.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF / Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "vect = TfidfVectorizer()\n",
    "\n",
    "pipe = Pipeline([('vect', vect), ('clf', mnb)])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "print('Baseline model accuracy (TF-IDF / MNB):', pipe.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'vect__ngram_range': [(1, 1), (1, 2), (1, 3),\n",
    "                                    (1, 4), (1, 5), (1, 6),\n",
    "                                    (2, 3), (2, 4), (2, 5),\n",
    "                                    (2, 6), (3, 3), (4, 4)],\n",
    "              'vect__analyzer': ['word', 'char', 'char_wb'],\n",
    "              'vect__norm': ['l1', 'l2'],\n",
    "              'clf__alpha': [0.0, 0.125, 0.25, 0.5, 0.75, 1.0],\n",
    "              'clf__fit_prior': [True, False]}\n",
    "search = RandomizedSearchCV(pipe, parameters, cv=5, n_iter=50, n_jobs=-1, verbose=False)\n",
    "results = search.fit(X_train, y_train)\n",
    "\n",
    "vect__ngram_range = results.best_params_['vect__ngram_range']\n",
    "vect__analyzer = results.best_params_['vect__analyzer']\n",
    "vect__norm = results.best_params_['vect__norm']\n",
    "clf__alpha = results.best_params_['clf__alpha']\n",
    "clf__fit_prior = results.best_params_['clf__fit_prior']\n",
    "\n",
    "print('Best Score:', results.best_score_)\n",
    "print('Achieved With Parameters:', results.best_params_)\n",
    "print('Evaluation (TF-IDF / MNB):', search.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSI / Random Forest Classifier (TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# Instantiate\n",
    "svd = TruncatedSVD()\n",
    "rfc = RandomForestClassifier()\n",
    "vect = TfidfVectorizer()\n",
    "\n",
    "lsi = Pipeline([('vect', vect), ('svd', svd)])\n",
    "\n",
    "pipe = Pipeline([('lsi', lsi), ('clf', rfc)])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "print('Baseline model accuracy (TF-IDF LSI / RFC):', pipe.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'lsi__vect__ngram_range': [(1, 1), (1, 2), (1, 3),\n",
    "                                         (1, 4), (1, 5), (1, 6),\n",
    "                                         (2, 3), (2, 4), (2, 5),\n",
    "                                         (2, 6), (3, 3), (4, 4)],\n",
    "              'lsi__vect__analyzer': ['word', 'char', 'char_wb'],\n",
    "              'lsi__vect__norm': ['l1', 'l2'],\n",
    "              'clf__criterion': ['gini', 'entropy']}\n",
    "search = RandomizedSearchCV(pipe, parameters, cv=5, n_iter=50, n_jobs=-1, verbose=False)\n",
    "results = search.fit(X_train, y_train)\n",
    "\n",
    "lsi__vect__ngram_range = results.best_params_['lsi__vect__ngram_range']\n",
    "lsi__vect__analyzer = results.best_params_['lsi__vect__analyzer']\n",
    "lsi__vect__norm = results.best_params_['lsi__vect__norm']\n",
    "clf__criterion = results.best_params_['clf__criterion']\n",
    "\n",
    "\n",
    "print('Best Score:', results.best_score_)\n",
    "print('Achieved With Parameters:', results.best_params_)\n",
    "print('Evaluation (TF-IDF LSI / RFC):', search.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'lsi__vect__ngram_range': [lsi__vect__ngram_range],\n",
    "              'lsi__vect__analyzer': [lsi__vect__analyzer],\n",
    "              'clf__criterion': [clf__criterion],\n",
    "              'lsi__vect__norm': [lsi__vect__norm],\n",
    "              'lsi__svd__n_components': [2, 5, 25, 50, 75, 100, 125, 150],\n",
    "              'lsi__svd__algorithm': ['arpack', 'randomized'],\n",
    "              'lsi__svd__n_iter': [5, 25, 50, 75, 100, 125, 150]}\n",
    "\n",
    "search = RandomizedSearchCV(pipe, parameters, n_iter=35, cv=5, n_jobs=-1, verbose=False)\n",
    "results = search.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "lsi__svd__n_components = results.best_params_['lsi__svd__n_components']\n",
    "lsi__svd__algorithm = results.best_params_['lsi__svd__algorithm']\n",
    "lsi__svd__n_iter = results.best_params_['lsi__svd__n_iter']\n",
    "\n",
    "print('Best Score:', results.best_score_)\n",
    "print('Achieved With Parameters:', results.best_params_)\n",
    "print('Evaluation (TF-IDF LSI / RFC):', search.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'lsi__vect__ngram_range': [lsi__vect__ngram_range],\n",
    "              'lsi__vect__analyzer': [lsi__vect__analyzer],\n",
    "              'lsi__vect__norm': [lsi__vect__norm],\n",
    "              'lsi__svd__n_components': [lsi__svd__n_components],\n",
    "              'lsi__svd__algorithm': [lsi__svd__algorithm],\n",
    "              'lsi__svd__n_iter': [lsi__svd__n_iter],\n",
    "              'clf__criterion': [clf__criterion],\n",
    "              'clf__max_depth': [None, 5, 10, 25, 50, 75, 100, 125, 150],\n",
    "              'clf__min_samples_split': [2, 5, 10, 25],\n",
    "              'clf__min_samples_leaf': [1, 3, 5, 7, 9, 12, 15]}\n",
    "\n",
    "search = RandomizedSearchCV(pipe, parameters, n_iter=30, cv=5, n_jobs=-1, verbose=False)\n",
    "results = search.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "lsi__svd__n_components = results.best_params_['lsi__svd__n_components']\n",
    "lsi__svd__algorithm = results.best_params_['lsi__svd__algorithm']\n",
    "lsi__svd__n_iter = results.best_params_['lsi__svd__n_iter']\n",
    "\n",
    "print('Best Score:', results.best_score_)\n",
    "print('Achieved With Parameters:', results.best_params_)\n",
    "print('Evaluation (TF-IDF LSI / RFC):', search.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CountVectorizer / RandomForestClassifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "vect = CountVectorizer()\n",
    "\n",
    "pipe = Pipeline([('vect', vect), ('clf', rfc)])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "print('Baseline model (CountVect / RFC):', pipe.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'vect__strip_accents': ['ascii', 'unicode', None],\n",
    "              'vect__ngram_range': [(1, 1), (1, 2), (1, 3),\n",
    "                                            (1, 4), (1, 5), (1, 6),\n",
    "                                            (2, 3), (2, 4), (2, 5),\n",
    "                                            (2, 6), (3, 3), (4, 4)],\n",
    "              'vect__analyzer': ['word', 'char', 'char_wb']}\n",
    "\n",
    "search = GridSearchCV(pipe, parameters, cv=5,  n_jobs=-1, verbose=False)\n",
    "results = search.fit(X_train, y_train)\n",
    "\n",
    "vect__ngram_range = results.best_params_['vect__ngram_range']\n",
    "vect__analyzer = results.best_params_['vect__analyzer']\n",
    "vect__strip_accents = results.best_params_['vect__strip_accents']\n",
    "\n",
    "print('Best Score:', results.best_score_)\n",
    "print('Achieved With Parameters:', results.best_params_)\n",
    "print('Evaluation:', search.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'vect__ngram_range': [vect__ngram_range],\n",
    "              'vect__analyzer': [vect__analyzer],\n",
    "              'vect__strip_accents': [vect__strip_accents],\n",
    "              'clf__n_estimators': [25, 50, 100, 125, 150, 175, 200],\n",
    "              'clf__max_features': [None, 'sqrt', 'log2', 50, 100, 200, 250],\n",
    "              'clf__max_samples': [None, 25, 35, 50, 65, 70, 100, 125],\n",
    "              'clf__class_weight': ['balanced', 'balanced_subsample'],\n",
    "              'clf__oob_score': [True, False]}\n",
    "\n",
    "search = RandomizedSearchCV(pipe, parameters, n_iter=40, cv=5, n_jobs=-1, verbose=False)\n",
    "results = search.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "clf__n_estimators = results.best_params_['clf__n_estimators']\n",
    "clf__max_features = results.best_params_['clf__max_features']\n",
    "clf__max_samples = results.best_params_['clf__max_samples']\n",
    "clf__class_weight = results.best_params_['clf__class_weight']\n",
    "clf__oob_score = results.best_params_['clf__oob_score']\n",
    "\n",
    "print('Best Score:', results.best_score_)\n",
    "print('Achieved With Parameters:', results.best_params_)\n",
    "print('Evaluation (CountVectorizer / RFC):', search.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CountVectorizer / Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb = MultinomialNB()\n",
    "vect = CountVectorizer()\n",
    "\n",
    "pipe = Pipeline([('vect', vect), ('clf', mnb)])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "print('Baseline model accuracy (CV/MNB):', pipe.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'vect__strip_accents': ['ascii', 'unicode', None],\n",
    "              'vect__ngram_range': [(1, 1), (1, 2), (1, 3),\n",
    "                                            (1, 4), (1, 5), (1, 6),\n",
    "                                            (2, 3), (2, 4), (2, 5),\n",
    "                                            (2, 6), (3, 3), (4, 4)],\n",
    "              'vect__analyzer': ['word', 'char', 'char_wb'],\n",
    "              'clf__alpha': [0.0, 0.125, 0.25, 0.5, 0.75, 1.0],\n",
    "              'clf__fit_prior': [True, False]}\n",
    "\n",
    "search = RandomizedSearchCV(pipe, parameters, cv=5, n_iter=40, n_jobs=-1, verbose=False)\n",
    "results = search.fit(X_train, y_train)\n",
    "\n",
    "vect__ngram_range = results.best_params_['vect__ngram_range']\n",
    "vect__analyzer = results.best_params_['vect__analyzer']\n",
    "vect__norm = results.best_params_['vect__norm']\n",
    "clf__alpha = results.best_params_['clf__alpha']\n",
    "clf__fit_prior = results.best_params_['clf__fit_prior']\n",
    "\n",
    "print('Best Score:', results.best_score_)\n",
    "print('Achieved With Parameters:', results.best_params_)\n",
    "print('Evaluation (CountVectorizer / MNB):', search.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSI / Random Forest Classifier (CountVectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate\n",
    "svd = TruncatedSVD()\n",
    "rfc = RandomForestClassifier()\n",
    "vect = CountVectorizer()\n",
    "\n",
    "lsi = Pipeline([('vect', vect), ('svd', svd)])\n",
    "\n",
    "pipe = Pipeline([('lsi', lsi), ('clf', rfc)])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'lsi__vect__strip_accents': ['ascii', 'unicode', None],\n",
    "              'lsi__vect__ngram_range': [(1, 1), (1, 2), (1, 3),\n",
    "                                         (1, 4), (1, 5), (1, 6),\n",
    "                                         (2, 3), (2, 4), (2, 5),\n",
    "                                         (2, 6), (3, 3), (4, 4)],\n",
    "              'lsi__vect__analyzer': ['word', 'char', 'char_wb']}\n",
    "\n",
    "search = RandomizedSearchCV(pipe, parameters, cv=5, n_iter=40, n_jobs=-1, verbose=False)\n",
    "results = search.fit(X_train, y_train)\n",
    "\n",
    "lsi__vect__strip_accents = results.best_params_['lsi__vect__strip_accents']\n",
    "lsi__vect__ngram_range = results.best_params_['lsi__vect__ngram_range']\n",
    "lsi__vect__analyzer = results.best_params_['lsi__vect__analyzer']\n",
    "\n",
    "print('Best Score:', results.best_score_)\n",
    "print('Achieved With Parameters:', results.best_params_)\n",
    "print('Evaluation:', search.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'lsi__vect__strip_accents': [lsi__vect__strip_accents],\n",
    "              'lsi__vect__analyzer': [lsi__vect__analyzer],\n",
    "              'lsi__vect__ngram_range': [lsi__vect__ngram_range],\n",
    "              'lsi__svd__n_components': [2, 5, 25, 50, 75, 100, 125, 150],\n",
    "              'lsi__svd__algorithm': ['arpack', 'randomized'],\n",
    "              'lsi__svd__n_iter': [5, 25, 50, 75, 100, 125, 150]}\n",
    "\n",
    "search = RandomizedSearchCV(pipe, parameters, n_iter=35, cv=5, n_jobs=-1, verbose=False)\n",
    "results = search.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "lsi__svd__n_components = results.best_params_['lsi__svd__n_components']\n",
    "lsi__svd__algorithm = results.best_params_['lsi__svd__algorithm']\n",
    "lsi__svd__n_iter = results.best_params_['lsi__svd__n_iter']\n",
    "\n",
    "print('Best Score:', results.best_score_)\n",
    "print('Achieved With Parameters:', results.best_params_)\n",
    "print('Evaluation:', search.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'lsi__vect__strip_accents': [lsi__vect__strip_accents],\n",
    "              'lsi__vect__analyzer': [lsi__vect__analyzer],\n",
    "              'lsi__vect__ngram_range': [lsi__vect__ngram_range],\n",
    "              'lsi__svd__n_components': [lsi__svd__n_components],\n",
    "              'lsi__svd__algorithm': [lsi__svd__algorithm],\n",
    "              'lsi__svd__n_iter': [lsi__svd__n_iter],\n",
    "              'clf__n_estimators': [25, 50, 100, 125, 150, 175, 200],\n",
    "              'clf__max_features': [None, 'sqrt', 'log2', 50, 100, 200, 250],\n",
    "              'clf__max_samples': [None, 25, 35, 50, 65, 70, 100, 125],\n",
    "              'clf__class_weight': ['balanced', 'balanced_subsample'],\n",
    "              'clf__oob_score': [True, False]}\n",
    "\n",
    "search = RandomizedSearchCV(pipe, parameters, n_iter=40, cv=5, n_jobs=-1, verbose=False)\n",
    "results = search.fit(X_train, y_train)\n",
    "\n",
    "print('Best Score:', results.best_score_)\n",
    "print('Achieved With Parameters:', results.best_params_)\n",
    "print('Evaluation (LSI + CountVectorizer / RFC):', search.score(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RedditPostHereBuild",
   "language": "python",
   "name": "redditpostherebuild"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
